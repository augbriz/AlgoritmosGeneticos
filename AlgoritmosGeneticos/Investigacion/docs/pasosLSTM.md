### Framework de Deep Learning**
**Fecha:** 5 de Agosto, 2025  
**Problema:** Â¿TensorFlow o PyTorch para implementar LSTM?

**DecisiÃ³n:** **TensorFlow con Keras**

**JustificaciÃ³n:**
- âœ… **Facilidad para principiantes:** API mÃ¡s intuitiva con Keras
- âœ… **DocumentaciÃ³n superior:** Mejor documentaciÃ³n para LSTM en series temporales
- âœ… **IntegraciÃ³n con AG:** MÃ¡s fÃ¡cil integraciÃ³n con algoritmos genÃ©ticos para optimizaciÃ³n de hiperparÃ¡metros
- âœ… **Ecosystem completo:** TensorBoard, mejor integraciÃ³n con numpy
- âœ… **Menos cÃ³digo:** ImplementaciÃ³n mÃ¡s directa para nuestro caso de uso

**Alternativa descartada:** PyTorch (mejor para investigaciÃ³n avanzada, pero mÃ¡s complejo para nuestro nivel)

---
## **ğŸš€ FASES DE IMPLEMENTACIÃ“N**

### **Fase 1: PreparaciÃ³n y ConfiguraciÃ³n** 
- [x] DecisiÃ³n de framework
- [ ] Importaciones y configuraciÃ³n inicial
- [ ] Carga y exploraciÃ³n de datos
- [ ] PreparaciÃ³n de datos para LSTM

### **Fase 2: ConstrucciÃ³n del Modelo**
- [ ] DiseÃ±o de arquitectura LSTM
- [ ] ConfiguraciÃ³n de hiperparÃ¡metros base
- [ ] CompilaciÃ³n del modelo
ğŸ”„ 1. NormalizaciÃ³n (0-1):
Â¿Por quÃ©? Las LSTM funcionan mejor con datos pequeÃ±os
MinMaxScaler: Convierte precios ($10-$50) â†’ valores (0.0-1.0)
Guardamos el scaler: Para "desnormalizar" las predicciones despuÃ©s
ğŸ—ï¸ 2. Secuencias Temporales:
Ventanas deslizantes: Ãšltimos 20 dÃ­as â†’ predice dÃ­a 21
Formato LSTM: Reshape a (samples, timesteps, features)
Ejemplo prÃ¡ctico:
âœ‚ï¸ 3. DivisiÃ³n Temporal (MUY IMPORTANTE):
NO aleatoria: Mantenemos orden temporal
Train: Datos mÃ¡s antiguos (pasado)
Validation: Datos intermedios
Test: Datos mÃ¡s recientes (futuro)
ğŸ“Š 4. VisualizaciÃ³n:
Antes vs. DespuÃ©s: Vemos el efecto de la normalizaciÃ³n
Control de calidad: Verificamos que todo estÃ© correcto
ğŸ’¡ Conceptos clave explicados:
Â¿Por quÃ© normalizar 0-1?

LSTM aprende mejor con nÃºmeros pequeÃ±os
Evita que precios altos ($50) dominen sobre precios bajos ($10)
Acelera el entrenamiento
Â¿Por quÃ© ventanas deslizantes?

LSTM necesita "contexto temporal"
20 dÃ­as de historia para predecir el dÃ­a 21
Es como decirle: "basÃ¡ndote en estas 20 observaciones, Â¿quÃ© pasarÃ¡ maÃ±ana?"

ğŸ¯ Diferencia entre ValidaciÃ³n y Test
ğŸ“Š DivisiÃ³n de datos tÃ­pica:

Total:Â 1000Â datosÂ deÂ YPFâ”œâ”€â”€Â TrainÂ (70%):Â 700Â datosÂ -Â EntrenarÂ elÂ modeloâ”œâ”€â”€Â ValidationÂ (15%):Â 150Â datosÂ -Â AjustarÂ hiperparÃ¡metrosÂ Â â””â”€â”€Â TestÂ (15%):Â 150Â datosÂ -Â EvaluaciÃ³nÂ final
ğŸ” Â¿Para quÃ© sirve cada conjunto?
ğŸ‹ï¸ Datos de ENTRENAMIENTO (Train):
PropÃ³sito: El modelo "aprende" de estos datos
AnalogÃ­a: Como estudiar con libros de texto
Â¿QuÃ© hace la LSTM? Ajusta sus pesos internos para minimizar errores
âš–ï¸ Datos de VALIDACIÃ“N:
PropÃ³sito: Ajustar hiperparÃ¡metros y evitar overfitting
AnalogÃ­a: Como hacer exÃ¡menes de prÃ¡ctica
Â¿QuÃ© hacemos? Probar diferentes configuraciones del modelo
ğŸ“ Datos de TEST:
PropÃ³sito: EvaluaciÃ³n final e imparcial del modelo
AnalogÃ­a: Como el examen final real
Â¿QuÃ© hacemos? Medir el rendimiento real del modelo


### **Fase 3: Entrenamiento y EvaluaciÃ³n**
- [ ] DivisiÃ³n de datos (train/val/test)
- [ ] Entrenamiento del modelo
- [ ] EvaluaciÃ³n de mÃ©tricas

Â¿Por quÃ© cada capa?

LSTM Layer 1: Aprende patrones temporales bÃ¡sicos (tendencias, ciclos)
Dropout: Evita overfitting (memorizar en lugar de aprender)
LSTM Layer 2: Aprende patrones mÃ¡s complejos y abstractos
Dense Layer: Convierte el "conocimiento" LSTM en una predicciÃ³n numÃ©rica

HiperparÃ¡metros principales:

LSTM Units	50	Neuronas por capa LSTM (mÃ¡s = mÃ¡s memoria)

Num Layers	2	Capas LSTM apiladas (mÃ¡s = mÃ¡s complejidad)

Dropout Rate	0.2	% de neuronas que se "apagan" (previene overfitting)

Learning Rate	0.001	Velocidad de aprendizaje

Batch Size	32	Datos procesados juntos

Epochs	100	Veces que ve todos los datos

3. CompilaciÃ³n del Modelo
Decisiones importantes:
Loss Function (FunciÃ³n de PÃ©rdida):

MSE (Mean Squared Error): Para predicciÃ³n de precios
Penaliza mÃ¡s los errores grandes
Optimizer (Optimizador):

Adam: Adapta la velocidad de aprendizaje automÃ¡ticamente
Mejor que SGD para nuestro caso
MÃ©tricas:

MAE: Error absoluto promedio (mÃ¡s interpretable)
MSE: Para seguimiento durante entrenamiento

ğŸš¨ 4. Callbacks (Controles Inteligentes)
Early Stopping:

EarlyStopping(Â Â Â Â monitor='val_loss',Â Â Â Â #Â VigilaÂ pÃ©rdidaÂ enÂ validaciÃ³nÂ Â Â Â patience=10,Â Â Â Â Â Â Â Â Â Â Â #Â EsperaÂ 10Â epochsÂ sinÂ mejoraÂ Â Â Â restore_best_weights=TrueÂ Â #Â MantieneÂ losÂ mejoresÂ pesos)
Â¿Por quÃ©? Evita entrenar de mÃ¡s (overfitting)

Reduce Learning Rate:

ReduceLROnPlateau(Â Â Â Â monitor='val_loss',Â Â Â Â factor=0.5,Â Â Â Â Â Â Â Â Â Â Â #Â ReduceÂ LRÂ aÂ laÂ mitadÂ Â Â Â patience=5Â Â Â Â Â Â Â Â Â Â Â Â #Â SiÂ noÂ mejoraÂ enÂ 5Â epochs)
Â¿Por quÃ©? Ajuste fino cuando se estanca


### **Fase 4: OptimizaciÃ³n con AG**
- [ ] ImplementaciÃ³n del algoritmo genÃ©tico
- [ ] DefiniciÃ³n del espacio de bÃºsqueda
- [ ] OptimizaciÃ³n de hiperparÃ¡metros

---